{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YVO-OrfDDOv",
        "outputId": "79124b1f-cb9b-4058-f112-3b8b9b5ff590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Collecting git+https://github.com/afnan47/cuda.git\n",
            "  Cloning https://github.com/afnan47/cuda.git to /tmp/pip-req-build-nexa5urh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/afnan47/cuda.git /tmp/pip-req-build-nexa5urh\n",
            "  Resolved https://github.com/afnan47/cuda.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4289 sha256=127a4f3d7fa31da8207dd50c7284ec87fa6297347c9cf6f7a97cdd92770792d6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6hh7lo4x/wheels/aa/f3/44/e10c1d226ec561d971fcd4b0463f6bff08602afa928a3e7bc7\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!pip install git+https://github.com/afnan47/cuda.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdlib>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void add(int* A, int* B, int* C, int size) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        C[tid] = A[tid] + B[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N;\n",
        "    cout << \"Enter the size of the vectors: \";\n",
        "    cin >> N;\n",
        "\n",
        "    int* A, * B, * C;\n",
        "    size_t vectorBytes = N * sizeof(int);\n",
        "\n",
        "    A = new int[N];\n",
        "    B = new int[N];\n",
        "    C = new int[N];\n",
        "\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        A[i] = rand() % 10;\n",
        "        B[i] = rand() % 10;\n",
        "    }\n",
        "\n",
        "    int* X, * Y, * Z;\n",
        "    cudaMalloc(&X, vectorBytes);\n",
        "    cudaMalloc(&Y, vectorBytes);\n",
        "    cudaMalloc(&Z, vectorBytes);\n",
        "\n",
        "    cudaMemcpy(X, A, vectorBytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(Y, B, vectorBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    add<<<1, N>>>(X, Y, Z, N);\n",
        "\n",
        "    cudaMemcpy(C, Z, vectorBytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout << \"Vector A:\";\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        cout << \" \" << A[i];\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    cout << \"Vector B:\";\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        cout << \" \" << B[i];\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    cout << \"Addition:\";\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        cout << \" \" << C[i];\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "\n",
        "    cudaFree(X);\n",
        "    cudaFree(Y);\n",
        "    cudaFree(Z);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Tk0Sg_FxFE2P",
        "outputId": "551c36dc-bac3-4633-bcdd-d3d7bfa0f9f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc add.cu -o add\n",
        "!./add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxypW7WDGjjH",
        "outputId": "3c7edbff-ebf9-4e87-9590-e9e023552fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the size of the vectors: 2\n",
            "Vector A: 3 7\n",
            "Vector B: 6 5\n",
            "Addition: 9 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_multi.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "const int N = 2;\n",
        "\n",
        "__global__ void matrixMultiply(int* A, int* B, int* C) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        int sum = 0;\n",
        "        for (int i = 0; i < N; ++i) {\n",
        "            sum += A[row * N + i] * B[i * N + col];\n",
        "        }\n",
        "        C[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int* A, * B, * C;\n",
        "    size_t matrixBytes = N * N * sizeof(int);\n",
        "\n",
        "    A = new int[N * N];\n",
        "    B = new int[N * N];\n",
        "    C = new int[N * N];\n",
        "\n",
        "    auto input = [&](int* matrix) {\n",
        "        cout << \"Enter elements of Matrix (\" << N << \"x\" << N << \"):\" << endl;\n",
        "        for (int i = 0; i < N * N; ++i) cin >> matrix[i];\n",
        "    };\n",
        "\n",
        "    input(A);\n",
        "    input(B);\n",
        "\n",
        "    int* X, * Y, * Z;\n",
        "    cudaMalloc(&X, matrixBytes);\n",
        "    cudaMalloc(&Y, matrixBytes);\n",
        "    cudaMalloc(&Z, matrixBytes);\n",
        "\n",
        "    cudaMemcpy(X, A, matrixBytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(Y, B, matrixBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    matrixMultiply<<<1, dim3(N, N)>>>(X, Y, Z);\n",
        "\n",
        "    cudaMemcpy(C, Z, matrixBytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout << \"Output- Matrix size: \" << N << \"x\" << N << endl;\n",
        "    cout << \"Input Matrix 1:\" << endl;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) cout << A[i * N + j] << \" \";\n",
        "        cout << endl;\n",
        "    }\n",
        "\n",
        "    cout << \"Input Matrix 2:\" << endl;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) cout << B[i * N + j] << \" \";\n",
        "        cout << endl;\n",
        "    }\n",
        "\n",
        "    cout << \"Resultant matrix:\" << endl;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) cout << C[i * N + j] << \" \";\n",
        "        cout << endl;\n",
        "    }\n",
        "\n",
        "    cout << \"Finished.\" << endl;\n",
        "\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "\n",
        "    cudaFree(X);\n",
        "    cudaFree(Y);\n",
        "    cudaFree(Z);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJyerXDCG1Gn",
        "outputId": "eec95517-0068-4230-b847-2c328208759e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_multi.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc matrix_multi.cu -o matrix_multi\n",
        "!./matrix_multi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAu7f_IJH5i_",
        "outputId": "668c972b-da43-497a-9b70-f6e9eb7b1a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter elements of Matrix (2x2):\n",
            "2 2\n",
            "2 2\n",
            "Enter elements of Matrix (2x2):\n",
            "4 4\n",
            "4 4\n",
            "Output- Matrix size: 2x2\n",
            "Input Matrix 1:\n",
            "2 2 \n",
            "2 2 \n",
            "Input Matrix 2:\n",
            "4 4 \n",
            "4 4 \n",
            "Resultant matrix:\n",
            "16 16 \n",
            "16 16 \n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile smma.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <climits>\n",
        "\n",
        "__global__ void min_reduction_kernel(int* arr, int size, int* result) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        atomicMin(result, arr[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void max_reduction_kernel(int* arr, int size, int* result) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        atomicMax(result, arr[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sum_reduction_kernel(int* arr, int size, int* result) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        atomicAdd(result, arr[tid]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    std::vector<int> arr = {5, 2, 9, 1, 7, 6, 8, 3, 4};\n",
        "    int size = arr.size();\n",
        "    int* d_arr;\n",
        "    int* d_result_min, * d_result_max, * d_result_sum;\n",
        "    int result_min = INT_MAX, result_max = INT_MIN, result_sum = 0;\n",
        "\n",
        "    cudaMalloc(&d_arr, size * sizeof(int));\n",
        "    cudaMemcpy(d_arr, arr.data(), size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    cudaMalloc(&d_result_min, sizeof(int));\n",
        "    cudaMalloc(&d_result_max, sizeof(int));\n",
        "    cudaMalloc(&d_result_sum, sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_result_min, &result_min, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_result_max, &result_max, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_result_sum, &result_sum, sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    min_reduction_kernel<<<(size + 255) / 256, 256>>>(d_arr, size, d_result_min);\n",
        "    max_reduction_kernel<<<(size + 255) / 256, 256>>>(d_arr, size, d_result_max);\n",
        "    sum_reduction_kernel<<<(size + 255) / 256, 256>>>(d_arr, size, d_result_sum);\n",
        "\n",
        "    cudaMemcpy(&result_min, d_result_min, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(&result_max, d_result_max, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaMemcpy(&result_sum, d_result_sum, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    std::cout << \"Minimum value: \" << result_min << std::endl;\n",
        "    std::cout << \"Maximum value: \" << result_max << std::endl;\n",
        "    std::cout << \"Sum: \" << result_sum << std::endl;\n",
        "    std::cout << \"Average: \" << static_cast<double>(result_sum) / size << std::endl;\n",
        "\n",
        "    cudaFree(d_arr);\n",
        "    cudaFree(d_result_min);\n",
        "    cudaFree(d_result_max);\n",
        "    cudaFree(d_result_sum);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CesJEOm0dVHn",
        "outputId": "bb4936ab-fdfc-41fe-be25-8350885276a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting smma.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc smma.cu -o smma\n",
        "!./smma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG_W20XHgF2t",
        "outputId": "ff26c8c6-cb52-405a-dccd-26f34df055fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value: 1\n",
            "Maximum value: 9\n",
            "Sum: 45\n",
            "Average: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile bfsdfs.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <queue>\n",
        "#include <stack>\n",
        "\n",
        "__global__ void bfs_kernel(int* adjList, int* visited, int* queue, int* queueSize, int n) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < *queueSize) {\n",
        "        int u = queue[tid];\n",
        "        if (!visited[u]) {\n",
        "            visited[u] = 1;\n",
        "            for (int i = adjList[u]; i < adjList[u + 1]; ++i) {\n",
        "                int v = adjList[i];\n",
        "                if (!visited[v]) {\n",
        "                    int idx = atomicAdd(queueSize, 1);\n",
        "                    queue[idx] = v;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void dfs_kernel(int* adjList, int* visited, int* stack, int* stackSize, int n) {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < *stackSize) {\n",
        "        int u = stack[tid];\n",
        "        if (!visited[u]) {\n",
        "            visited[u] = 1;\n",
        "            for (int i = adjList[u]; i < adjList[u + 1]; ++i) {\n",
        "                int v = adjList[i];\n",
        "                if (!visited[v]) {\n",
        "                    int idx = atomicAdd(stackSize, 1);\n",
        "                    stack[idx] = v;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n, m;\n",
        "    std::cout << \"Enter the number of vertices: \";\n",
        "    std::cin >> n;\n",
        "    std::cout << \"Enter the number of edges: \";\n",
        "    std::cin >> m;\n",
        "\n",
        "    // Assuming graph is represented as an adjacency list\n",
        "    std::vector<std::vector<int>> adjList(n + 1);\n",
        "    std::cout << \"Enter the edges (format: u v):\\n\";\n",
        "    for (int i = 0; i < m; ++i) {\n",
        "        int u, v;\n",
        "        std::cin >> u >> v;\n",
        "        adjList[u].push_back(v);\n",
        "        adjList[v].push_back(u); // Assuming an undirected graph\n",
        "    }\n",
        "\n",
        "    // Allocate memory on the GPU\n",
        "    int* d_adjList, * d_visited, * d_queue, * d_queueSize, * d_stack, * d_stackSize;\n",
        "    cudaMalloc(&d_adjList, (2 * m) * sizeof(int)); // Each edge is stored twice in the adjacency list\n",
        "    cudaMalloc(&d_visited, n * sizeof(int));\n",
        "    cudaMalloc(&d_queue, n * sizeof(int));\n",
        "    cudaMalloc(&d_queueSize, sizeof(int));\n",
        "    cudaMalloc(&d_stack, n * sizeof(int));\n",
        "    cudaMalloc(&d_stackSize, sizeof(int));\n",
        "\n",
        "    // Initialize data on the GPU\n",
        "\n",
        "    // Perform BFS traversal\n",
        "    int start;\n",
        "    std::cout << \"Enter the starting vertex for BFS: \";\n",
        "    std::cin >> start;\n",
        "    cudaMemcpy(d_queue, &start, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_queueSize, &start, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    int queueSize = 1;\n",
        "    while (queueSize > 0) {\n",
        "        bfs_kernel<<<(queueSize + 255) / 256, 256>>>(d_adjList, d_visited, d_queue, d_queueSize, n);\n",
        "        cudaMemcpy(&queueSize, d_queueSize, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    }\n",
        "\n",
        "    // Perform DFS traversal\n",
        "    std::cout << \"Enter the starting vertex for DFS: \";\n",
        "    std::cin >> start;\n",
        "    cudaMemcpy(d_visited, &start, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_stack, &start, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_stackSize, &start, sizeof(int), cudaMemcpyHostToDevice);\n",
        "    int stackSize = 1;\n",
        "    while (stackSize > 0) {\n",
        "        dfs_kernel<<<(stackSize + 255) / 256, 256>>>(d_adjList, d_visited, d_stack, d_stackSize, n);\n",
        "        cudaMemcpy(&stackSize, d_stackSize, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    }\n",
        "\n",
        "    // Copy visited array back to host\n",
        "    int* h_visited = new int[n];\n",
        "    cudaMemcpy(h_visited, d_visited, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print BFS traversal result\n",
        "    std::cout << \"BFS traversal starting from vertex \" << start << \":\\n\";\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        if (h_visited[i]) {\n",
        "            std::cout << i << \" \";\n",
        "        }\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    // Print DFS traversal result\n",
        "    std::cout << \"DFS traversal starting from vertex \" << start << \":\\n\";\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        if (h_visited[i]) {\n",
        "            std::cout << i << \" \";\n",
        "        }\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    delete[] h_visited;\n",
        "\n",
        "    // Free memory on the GPU\n",
        "    cudaFree(d_adjList);\n",
        "    cudaFree(d_visited);\n",
        "    cudaFree(d_queue);\n",
        "    cudaFree(d_queueSize);\n",
        "    cudaFree(d_stack);\n",
        "    cudaFree(d_stackSize);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5drxN8cg3Yf",
        "outputId": "29810f28-8d9e-4a02-950f-087c1e21c145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting bfsdfs.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc bfsdfs.cu -o bfsdfs\n",
        "!./bfsdfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYTuzehWjZa9",
        "outputId": "7bbc2c31-94c9-4cbc-bf43-7a3d176683df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of vertices: 5\n",
            "Enter the number of edges: 6\n",
            "Enter the edges (format: u v):\n",
            "0 1\n",
            "0 2\n",
            "1 3\n",
            "1 4\n",
            "2 4\n",
            "3 4\n",
            "Enter the starting vertex for BFS: 0\n",
            "Enter the starting vertex for DFS: 0\n",
            "BFS traversal starting from vertex 0:\n",
            "\n",
            "DFS traversal starting from vertex 0:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile bubblesort.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "\n",
        "__global__ void bubbleSortParallel(int* arr, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n - 1) {\n",
        "        if (arr[idx] > arr[idx + 1]) {\n",
        "            int temp = arr[idx];\n",
        "            arr[idx] = arr[idx + 1];\n",
        "            arr[idx + 1] = temp;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void bubbleSortSerial(std::vector<int>& arr) {\n",
        "    int n = arr.size();\n",
        "    bool swapped = true;\n",
        "    while (swapped) {\n",
        "        swapped = false;\n",
        "        for (int i = 0; i < n - 1; i++) {\n",
        "            if (arr[i] > arr[i + 1]) {\n",
        "                std::swap(arr[i], arr[i + 1]);\n",
        "                swapped = true;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 10000;\n",
        "    int block_size = 256;\n",
        "    int num_blocks = (n + block_size - 1) / block_size;\n",
        "\n",
        "    std::vector<int> arr(n);\n",
        "\n",
        "    // Initialize array with random values\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        arr[i] = rand() % 10000;\n",
        "    }\n",
        "\n",
        "    // Measure serial Bubble Sort performance\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    bubbleSortSerial(arr);\n",
        "    auto stop = std::chrono::high_resolution_clock::now();\n",
        "    auto durationSerial = std::chrono::duration_cast<std::chrono::milliseconds>(stop - start);\n",
        "\n",
        "    std::cout << \"Serial Bubble Sort took \" << durationSerial.count() << \" milliseconds.\" << std::endl;\n",
        "\n",
        "    // Reset array for parallel sort\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        arr[i] = rand() % 10000;\n",
        "    }\n",
        "\n",
        "    int* d_arr;\n",
        "    cudaMalloc(&d_arr, n * sizeof(int));\n",
        "    cudaMemcpy(d_arr, arr.data(), n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Measure parallel Bubble Sort performance\n",
        "    start = std::chrono::high_resolution_clock::now();\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        bubbleSortParallel<<<num_blocks, block_size>>>(d_arr, n);\n",
        "        cudaDeviceSynchronize();\n",
        "    }\n",
        "    stop = std::chrono::high_resolution_clock::now();\n",
        "    auto durationParallel = std::chrono::duration_cast<std::chrono::milliseconds>(stop - start);\n",
        "\n",
        "    std::cout << \"Parallel Bubble Sort took \" << durationParallel.count() << \" milliseconds.\" << std::endl;\n",
        "\n",
        "    cudaMemcpy(arr.data(), d_arr, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaFree(d_arr);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "2NtJcj6fjbrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473ad373-f3a7-4564-88e5-4a29c991c3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting bubblesort.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc bubblesort.cu -o bubblesort\n",
        "!./bubblesort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAAZEUlFFnmi",
        "outputId": "e1d63a9b-fbe5-4ba3-d8bf-3963dc68f281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serial Bubble Sort took 1183 milliseconds.\n",
            "Parallel Bubble Sort took 138 milliseconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mergesort.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "\n",
        "// Serial merge sort implementation\n",
        "void merge(int* arr, int l, int m, int r) {\n",
        "    // Merge logic\n",
        "}\n",
        "\n",
        "void mergeSort(int* arr, int l, int r) {\n",
        "    // Merge sort logic\n",
        "}\n",
        "\n",
        "// Parallel merge sort implementation\n",
        "__global__ void mergeSortParallel(int* arr, int l, int r) {\n",
        "    // Merge sort logic\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 10000;\n",
        "    int block_size = 256;\n",
        "    int num_blocks = (n + block_size - 1) / block_size;\n",
        "\n",
        "    std::vector<int> arr_serial(n);\n",
        "    std::vector<int> arr_parallel(n);\n",
        "\n",
        "    // Initialize arrays with random values\n",
        "    // Copy values from arr_serial to arr_parallel for comparison\n",
        "\n",
        "    // Serial merge sort\n",
        "    auto start_serial = std::chrono::high_resolution_clock::now();\n",
        "    mergeSort(arr_serial.data(), 0, n - 1);\n",
        "    auto end_serial = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    // Parallel merge sort\n",
        "    int* d_arr;\n",
        "    cudaMalloc(&d_arr, n * sizeof(int));\n",
        "    cudaMemcpy(d_arr, arr_parallel.data(), n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    auto start_parallel = std::chrono::high_resolution_clock::now();\n",
        "    mergeSortParallel<<<num_blocks, block_size>>>(d_arr, 0, n - 1);\n",
        "    cudaDeviceSynchronize();\n",
        "    auto end_parallel = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    cudaMemcpy(arr_parallel.data(), d_arr, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaFree(d_arr);\n",
        "\n",
        "    // Print timing information\n",
        "    std::chrono::duration<double, std::milli> duration_serial = end_serial - start_serial;\n",
        "    std::cout << \"Serial Merge Sort took \" << duration_serial.count() << \" milliseconds.\" << std::endl;\n",
        "\n",
        "    std::chrono::duration<double, std::milli> duration_parallel = end_parallel - start_parallel;\n",
        "    std::cout << \"Parallel Merge Sort took \" << duration_parallel.count() << \" milliseconds.\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "hZBMf1qXFqRx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "752f6067-889c-499a-ac45-b586d745d1f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mergesort.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc mergesort.cu -o mergesort\n",
        "!./mergesort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yzB5yBqLfFGM",
        "outputId": "6aae75f8-9d0f-4c7e-f355-42fc7e3ca054"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serial Merge Sort took 0.000134 milliseconds.\n",
            "Parallel Merge Sort took 0.19186 milliseconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bP1Rwq51fI86"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}